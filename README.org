| *Official homepage* | [[https://ahc.leeds.ac.uk/languages/staff/1137/dr-serge-sharoff]] |
| *Google Scholar:*   | [[https://scholar.google.co.uk/citations?user=qcnf4QsAAAAJ]]      |
| *Semantic Scholar:* | [[https://www.semanticscholar.org/author/S.-Sharoff/2506104]]     |

** My research interests
   :PROPERTIES:
   :CUSTOM_ID: my-research-interests
   :END:
Artificial Intelligence and more specifically Large Language Models,
such as ChatGPT, have recently made a profound impact on how we interact
with the computers by providing the ability to produce new texts in
response to prompts. Fundamental research in this area is at the core of
my expertise, I've been doing this since my own PhD in the 1990s. This pre-dated LLMs, but the idea of linking [[../publications/1999-interact.pdf][language to meanings]] remains the same.
One of my recent papers on the [[./publications/2020-LREC-anatomy.pdf][diversity of texts on the Web]] has been cited by some of the [[https://arxiv.org/abs/2212.14578][GPT creators from OpenAI]]. See also [[./GPT-collection.html][my collection of curious cases]] of testing ChatGPT in a range of scenarios.

My research interests are related to three domains: linguistics, computer science and cognitive science.

Probably the most interesting bit in my recent research is in digital curation of corpora from the web, cf.
the set of available large corpora and the procedure described at
[[http://corpus.leeds.ac.uk/internet.html]], see [[./publications/2006-ijcl-proof.pdf][the full paper]].
The current set of resources includes multi-million word corpora for Chinese, English,
French, German, Italian, Polish, Portuguese, Russian and Spanish.

Web corpora can be curated in terms of domains and
[[file:webgenres/][genres]], and also via automatic annotation for their linguistic properties, such as parts
of speech, syntactic relations or named entities. The resources for
developing statistical models are relatively modest for many languages,
so I research methods for bootstraping them from related languages, for
example, from [[file:publications/2011-dialog-sharoff-nivre.pdf][Russian]] to [[file:publications/2016-HyTra.pdf][Ukrainian]] or from [[./publications/2011-clia-indian.pdf][Telugu to Kannada]].

Another aspect of Web corpus curation concerns developing frequency lists. While it is easy to count the number of times each word occurs in a corpus, this can lead to undesirable frequency bursts, as a word can be used too often in a small number of files. Please see the paper and check my [[./frqc/][reliable frequency lists]]
obtained for several corpora and several languages. See also the [[./kelly/][pedagogical frequency lists]] produced as the outcome of the [[https://spraakbanken.gu.se/en/projects/kelly][Kelly project]].

Another example is [[http://ucrel.lancs.ac.uk/projects/assist/][ASSIST]], a joint project
with Lancaster University, which is about an automatic procedure for
finding translation equivalent using large comparable corpora
(consisting of texts which are not translations of each other). See a
[[https://comparable.limsi.fr/][series of BUCC workshops]] and a
[[https://link.springer.com/book/10.1007/978-3-031-31384-4][recent book]] on the topic. [[file:publications/2023-bucc-intro.pdf][Its introduction]] is available from my list of [[file:publications/][publications]].

My approach in linguistics rests on the assumption that language is the
resource for exchanging meanings. My interests in linguistics stretch
from contrastive semantics (how to study words that are used to mean
things in different ways in different languages) to corpus linguistics
(how to study real uses of words in their contexts) to computational
linguistics (how to dewsign computational models for natural language
understanding and generation). See also the page with my tools for
[[../webgenres/][corpus collection and processing]].

My interests in [[file:communication.html][communication studies]] focus
on social practices of communities of language speakers, which result in
creation and maintenance of meanings in the intersubjective space of
people conducting communication, primarily in the context of [[http://www.isfla.org/Systemics/definition.html][Halliday's Systemic-Functional Linguistics]]. This is directly relevant to understanding when and how large language models are likely to fail in the form of biases and hallucinations, because via pre-training on very large corpora the LLMs have acquired very good knowledge of linguistic resources used for communication without understanding the conditions under which the corresponding texts have been produced.

The most convenient access to the list of my publications is via
[[https://scholar.google.com/citations?user=qcnf4QsAAAAJ&view_op=list_works&sortby=pubdate][Google Scholar]]. The list of my available publications is also available from [[./publications/][this page]].

See my formal [[file:cv-formal.pdf][CV]] as well as my
[[file:lineage.html][academic genealogy]] (the list through my
supervisors can be traced back to Leibniz, Poisson and Gauss).

** PhD projects
   :PROPERTIES:
   :CUSTOM_ID: phd-projects
   :END:
I am happy to consider applications from prospective PhD students in the
area of my expertise. The following general topics are preferable:

*** Automatic Text Classification for Translation
    :PROPERTIES:
    :CUSTOM_ID: automatic-text-classification-for-translation
    :END:
Setting up a translation project usually involves assessing the amount
of time required for translating a text and selecting the most suitable
translator. Modern approaches in Language Technology can do wonders with
text processing, but it is not clear how helpful they can be in the
translation settings. For example, can they help to determine the genre
of a text, its difficulty or suitability to translators? Similar text
classification tools can be also used for tasks related to learning
foreign languages.

/Background references/:

- Serge Sharoff. [[file:publications/2021-register.pdf][Genre Annotation for the Web: text-external and text-internal perspectives]]. /Register Studies/. 2021
- Serge Sharoff. [[file:publications/2018-ftd.pdf][Functional text dimensions for the annotation of Web corpora]]. /Corpora/, 13(1):65--95, 2018
- Yu Yuan and Serge Sharoff. [[file:publications/2020-LREC-htqe.pdf][Sentence Level Human Translation Quality Estimation with Attention-based Neural Networks]]. In Proc International Conference on Language Resources and Evaluation (LREC'20), Marseilles, May 2020

*** Language adaptation for improving models of lesser-resourced languages
    :PROPERTIES:
    :CUSTOM_ID: language-adaptation-for-improving-models-of-lesser-resourced-languages
    :END:
A translation model needs to be applicable to a large number of
languages, while the training resources or linguistic models are often
better developed only for some languages. Language adaptation can be
designed in a way similar to domain adaptation to improve the models of
lesser-resourced languages by taking into account the resources
available for closely related languages, e.g., from French to Romanian.
This can be applied in a range of training scenarios, such as
Part-Of-Speech tagging, text classification, translation quality
prediction, etc.

/Background references:/

- Serge Sharoff. [[file:publications/2019-jnle.pdf][Finding next of kin: Cross-lingual embedding spaces for related languages]]. /Journal of Natural Language Engineering/, 25, 2019
- Miguel Rios and Serge Sharoff. [[file:publications/2016-pbml.pdf][Language adaptation for extending post-editing estimates for closely  related languages]]. /The Prague Bulletin of Mathematical Linguistics/, 106:181-192, 2016

*** Non-parallel resources for translation
    :PROPERTIES:
    :CUSTOM_ID: non-parallel-resources-for-translation
    :END:
Modern Machine Translation is based on "plagiarising" large amounts of
existing translations, which usually come from institutions such as the
United Nations or the European Parliament. This is not enough for many
language directions or for specific domains, such as biomedicine. What
are productive methods to mine information about translations from
non-parallel texts, such as Wikipedia articles on the same topic or news
wire streams in different languages?

/Background references:/

- Serge Sharoff. [[file:publications/2020-LREC-anatomy.pdf][Know thy   corpus! Robust methods for digital curation of Web corpora]]. In Proc  LREC, Marseilles, May 2020
- Maria Kunilovskaya and Serge Sharoff. [[file:publications/2019-RANLP.pdf][Building functionally similar corpus resources for  translation studies]]. In Proc RANLP, Varna, September 2019
- Pierre Zweigenbaum, Serge Sharoff, and Reinhard Rapp. [[file:publications/2018-lrec-bucc.pdf][A multilingual dataset for evaluating  parallel sentence extraction from comparable corpora]] In Proc LREC, Miyazaki, Japan, May 2018

I have also prepared a [[https://link.springer.com/book/10.1007/978-3-031-31384-4][textbook on Comparable Corpora]] published in the Synthesis Lecture Series. The [[file:publications/2023-bucc-intro.pdf][introduction to the book]] is available.
